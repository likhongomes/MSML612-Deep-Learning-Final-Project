{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "QTw6l4gwka_X"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tab_transformer_pytorch import TabTransformer\n",
    "import numpy as np\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w86mXwgDumqS"
   },
   "source": [
    "Note: Data is from https://opendata.dc.gov/ and the dataset from September 2023 is missing\n",
    "Metadata: https://www.arcgis.com/sharing/rest/content/items/17d73d958f8247e19a4885a4d8bce9dd/info/metadata/metadata.xml?format=default&output=html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "aZ1FjWAIoB5f"
   },
   "outputs": [],
   "source": [
    "def load_parking_violation_data(data_folder):\n",
    "    files = os.listdir(data_folder)\n",
    "    print(files)\n",
    "    all_csvs = glob.glob(os.path.join(data_folder, \"*.csv\"))\n",
    "    dfs = []\n",
    "    for c in all_csvs:\n",
    "        try:\n",
    "          df = pd.read_csv(c)\n",
    "          dfs.append(df)\n",
    "          print(f\"successfully loaded {c}\")\n",
    "        except Exception as e:\n",
    "          print(f\"error opening {c}: {e}\")\n",
    "    return pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JsFDaETspQ6u",
    "outputId": "aa6cd209-5953-4dac-970c-a27012f34c00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cleaned_parking_violations_v2.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5n/jjx2myys12g9lmz1yqf0txth0000gn/T/ipykernel_84961/2234199005.py:8: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(c)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded ../CleanData/cleaned_parking_violations_v2.csv\n"
     ]
    }
   ],
   "source": [
    "df = load_parking_violation_data(\"../CleanData\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the length of the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZmaUQJuyphfg",
    "outputId": "bf315f34-b639-47bf-d0fa-92a8201447e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1094297"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objectid</th>\n",
       "      <th>ticket_number</th>\n",
       "      <th>issuing_agency_code</th>\n",
       "      <th>issuing_agency_name</th>\n",
       "      <th>issuing_agency_short</th>\n",
       "      <th>violation_code</th>\n",
       "      <th>location</th>\n",
       "      <th>plate_state</th>\n",
       "      <th>disposition_code</th>\n",
       "      <th>disposition_type</th>\n",
       "      <th>...</th>\n",
       "      <th>violation_type_desc</th>\n",
       "      <th>issue_datetime</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>Unnamed: 29</th>\n",
       "      <th>is_fleet_gov_or_rental</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84395696</td>\n",
       "      <td>275257905</td>\n",
       "      <td>50</td>\n",
       "      <td>FEDERAL PROTECTIVE SERVICES (US GV)</td>\n",
       "      <td>FPS</td>\n",
       "      <td>P055</td>\n",
       "      <td>SIDE 1201 CONSTITUTION AVE NW</td>\n",
       "      <td></td>\n",
       "      <td>134</td>\n",
       "      <td>Dismissed</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-06-17 12:28:00</td>\n",
       "      <td>2025</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84395698</td>\n",
       "      <td>275697181</td>\n",
       "      <td>4</td>\n",
       "      <td>METROPOLITAN POLICE DPT-DISTRICT 4</td>\n",
       "      <td>MPD-4D</td>\n",
       "      <td>P170</td>\n",
       "      <td>600 BLK OTIS PL NW</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-06-20 23:38:00</td>\n",
       "      <td>2025</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>Friday</td>\n",
       "      <td>23</td>\n",
       "      <td>False</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84395699</td>\n",
       "      <td>275697203</td>\n",
       "      <td>4</td>\n",
       "      <td>METROPOLITAN POLICE DPT-DISTRICT 4</td>\n",
       "      <td>MPD-4D</td>\n",
       "      <td>P170</td>\n",
       "      <td>600 BLK OTIS PL NW</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-06-20 23:54:00</td>\n",
       "      <td>2025</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>Friday</td>\n",
       "      <td>23</td>\n",
       "      <td>False</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84395717</td>\n",
       "      <td>276503242</td>\n",
       "      <td>50</td>\n",
       "      <td>FEDERAL PROTECTIVE SERVICES (US GV)</td>\n",
       "      <td>FPS</td>\n",
       "      <td>P269</td>\n",
       "      <td>NS 600 BLK MARYLAND AVE SW</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-06-04 07:45:00</td>\n",
       "      <td>2025</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84395718</td>\n",
       "      <td>276503253</td>\n",
       "      <td>50</td>\n",
       "      <td>FEDERAL PROTECTIVE SERVICES (US GV)</td>\n",
       "      <td>FPS</td>\n",
       "      <td>P168</td>\n",
       "      <td>NS 600 BLK MARYLAND AVE SW</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-06-04 07:45:00</td>\n",
       "      <td>2025</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   objectid  ticket_number  issuing_agency_code  \\\n",
       "0  84395696      275257905                   50   \n",
       "1  84395698      275697181                    4   \n",
       "2  84395699      275697203                    4   \n",
       "3  84395717      276503242                   50   \n",
       "4  84395718      276503253                   50   \n",
       "\n",
       "                   issuing_agency_name issuing_agency_short violation_code  \\\n",
       "0  FEDERAL PROTECTIVE SERVICES (US GV)                  FPS           P055   \n",
       "1   METROPOLITAN POLICE DPT-DISTRICT 4               MPD-4D           P170   \n",
       "2   METROPOLITAN POLICE DPT-DISTRICT 4               MPD-4D           P170   \n",
       "3  FEDERAL PROTECTIVE SERVICES (US GV)                  FPS           P269   \n",
       "4  FEDERAL PROTECTIVE SERVICES (US GV)                  FPS           P168   \n",
       "\n",
       "                        location plate_state  disposition_code  \\\n",
       "0  SIDE 1201 CONSTITUTION AVE NW                           134   \n",
       "1             600 BLK OTIS PL NW                             0   \n",
       "2             600 BLK OTIS PL NW                             0   \n",
       "3     NS 600 BLK MARYLAND AVE SW                             0   \n",
       "4     NS 600 BLK MARYLAND AVE SW                             0   \n",
       "\n",
       "  disposition_type  ...  violation_type_desc       issue_datetime  year  \\\n",
       "0        Dismissed  ...                  NaN  2025-06-17 12:28:00  2025   \n",
       "1            Other  ...                  NaN  2025-06-20 23:38:00  2025   \n",
       "2            Other  ...                  NaN  2025-06-20 23:54:00  2025   \n",
       "3            Other  ...                  NaN  2025-06-04 07:45:00  2025   \n",
       "4            Other  ...                  NaN  2025-06-04 07:45:00  2025   \n",
       "\n",
       "   month  day  day_of_week  hour  is_weekend  Unnamed: 29  \\\n",
       "0      6   17      Tuesday    12       False      UNKNOWN   \n",
       "1      6   20       Friday    23       False      UNKNOWN   \n",
       "2      6   20       Friday    23       False      UNKNOWN   \n",
       "3      6    4    Wednesday     7       False      UNKNOWN   \n",
       "4      6    4    Wednesday     7       False      UNKNOWN   \n",
       "\n",
       "  is_fleet_gov_or_rental  \n",
       "0                   True  \n",
       "1                   True  \n",
       "2                   True  \n",
       "3                   True  \n",
       "4                   True  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5n/jjx2myys12g9lmz1yqf0txth0000gn/T/ipykernel_84961/1993024186.py:8: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df['hour_bin'] = df['issue_datetime'].dt.floor('1H')\n"
     ]
    }
   ],
   "source": [
    "# parse datetime\n",
    "df['issue_datetime'] = pd.to_datetime(df['issue_datetime'])\n",
    "cell = 0.001\n",
    "# =========================\n",
    "# 2) SPATIOTEMPORAL BINNING\n",
    "# =========================\n",
    "# hourly bins for time\n",
    "df['hour_bin'] = df['issue_datetime'].dt.floor('1H')\n",
    "\n",
    "# spatial bins (~100m cells)\n",
    "cell = 0.001  # adjust for desired grid size\n",
    "df['lat_bin'] = (df['latitude'] // cell) * cell\n",
    "df['lon_bin'] = (df['longitude'] // cell) * cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5n/jjx2myys12g9lmz1yqf0txth0000gn/T/ipykernel_84961/561210117.py:4: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  hours = pd.date_range(df['hour_bin'].min(), df['hour_bin'].max(), freq='1H')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m lat_bins \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat_bin\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m      6\u001b[0m lon_bins \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon_bin\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[0;32m----> 8\u001b[0m grid \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(product(hours, lat_bins, lon_bins),\n\u001b[1;32m      9\u001b[0m                     columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhour_bin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat_bin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon_bin\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# label positive if ≥ 1 ticket\u001b[39;00m\n\u001b[1;32m     12\u001b[0m hits \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhour_bin\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat_bin\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon_bin\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;241m.\u001b[39mrename(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mticket_count\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/frame.py:851\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m--> 851\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m nested_data_to_arrays(\n\u001b[1;32m    852\u001b[0m         \u001b[38;5;66;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;00m\n\u001b[1;32m    853\u001b[0m         \u001b[38;5;66;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;00m\n\u001b[1;32m    854\u001b[0m         data,\n\u001b[1;32m    855\u001b[0m         columns,\n\u001b[1;32m    856\u001b[0m         index,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    857\u001b[0m         dtype,\n\u001b[1;32m    858\u001b[0m     )\n\u001b[1;32m    859\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    860\u001b[0m         arrays,\n\u001b[1;32m    861\u001b[0m         columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    864\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    865\u001b[0m     )\n\u001b[1;32m    866\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/internals/construction.py:520\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    518\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[0;32m--> 520\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m to_arrays(data, columns, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    521\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/internals/construction.py:845\u001b[0m, in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    842\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m    843\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _list_to_arrays(data)\n\u001b[0;32m--> 845\u001b[0m content, columns \u001b[38;5;241m=\u001b[39m _finalize_columns_and_data(arr, columns, dtype)\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/internals/construction.py:945\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    942\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[0;32m--> 945\u001b[0m     contents \u001b[38;5;241m=\u001b[39m convert_object_array(contents, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    947\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m contents, columns\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/internals/construction.py:1070\u001b[0m, in \u001b[0;36mconvert_object_array\u001b[0;34m(content, dtype, dtype_backend, coerce_float)\u001b[0m\n\u001b[1;32m   1066\u001b[0m             arr \u001b[38;5;241m=\u001b[39m maybe_cast_to_datetime(arr, dtype)\n\u001b[1;32m   1068\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\n\u001b[0;32m-> 1070\u001b[0m arrays \u001b[38;5;241m=\u001b[39m [convert(arr) \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m content]\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/core/internals/construction.py:1030\u001b[0m, in \u001b[0;36mconvert_object_array.<locals>.convert\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconvert\u001b[39m(arr):\n\u001b[1;32m   1029\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1030\u001b[0m         arr \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(\n\u001b[1;32m   1031\u001b[0m             arr,\n\u001b[1;32m   1032\u001b[0m             try_float\u001b[38;5;241m=\u001b[39mcoerce_float,\n\u001b[1;32m   1033\u001b[0m             convert_to_nullable_dtype\u001b[38;5;241m=\u001b[39mdtype_backend \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1034\u001b[0m         )\n\u001b[1;32m   1035\u001b[0m         \u001b[38;5;66;03m# Notes on cases that get here 2023-02-15\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m         \u001b[38;5;66;03m# 1) we DO get here when arr is all Timestamps and dtype=None\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m         \u001b[38;5;66;03m# 2) disabling this doesn't break the world, so this must be\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m         \u001b[38;5;66;03m#    getting caught at a higher level\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m         \u001b[38;5;66;03m# 3) passing convert_non_numeric to maybe_convert_objects get this right\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;66;03m# 4) convert_non_numeric?\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 3) CREATE FULL GRID\n",
    "# =========================\n",
    "hours = pd.date_range(df['hour_bin'].min(), df['hour_bin'].max(), freq='1H')\n",
    "lat_bins = df['lat_bin'].unique()\n",
    "lon_bins = df['lon_bin'].unique()\n",
    "\n",
    "grid = pd.DataFrame(product(hours, lat_bins, lon_bins),\n",
    "                    columns=['hour_bin', 'lat_bin', 'lon_bin'])\n",
    "\n",
    "# label positive if ≥ 1 ticket\n",
    "hits = df.groupby(['hour_bin','lat_bin','lon_bin']).size().rename('ticket_count').reset_index()\n",
    "X = grid.merge(hits, on=['hour_bin','lat_bin','lon_bin'], how='left').fillna({'ticket_count': 0})\n",
    "X['label'] = (X['ticket_count'] > 0).astype(int)\n",
    "\n",
    "# =========================\n",
    "# 4) FEATURES FOR MODEL\n",
    "# =========================\n",
    "X['dayofweek'] = X['hour_bin'].dt.dayofweek\n",
    "X['hour']      = X['hour_bin'].dt.hour\n",
    "X['hour_sin']  = np.sin(2*np.pi*X['hour']/24)\n",
    "X['hour_cos']  = np.cos(2*np.pi*X['hour']/24)\n",
    "\n",
    "cat_cols  = ['dayofweek']                 # could also bucket lat/lon into discrete categories\n",
    "cont_cols = ['hour_sin','hour_cos','lat_bin','lon_bin']\n",
    "target_col = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cat_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Map categories to integer IDs\u001b[39;00m\n\u001b[1;32m      2\u001b[0m category_map \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cat_cols:\n\u001b[1;32m      4\u001b[0m     df[col] \u001b[38;5;241m=\u001b[39m df[col]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m     category_map[col] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(df[col]\u001b[38;5;241m.\u001b[39mcat\u001b[38;5;241m.\u001b[39mcategories)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cat_cols' is not defined"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 5) ENCODE & NORMALIZE\n",
    "# =========================\n",
    "cat_cols  = ['day_of_week', 'year', 'month', 'hour', 'issue_datetime', 'latitude', 'longitude']\n",
    "\n",
    "category_sizes = []\n",
    "for col in cat_cols:\n",
    "    X[col] = X[col].astype('category')\n",
    "    category_sizes.append(len(X[col].cat.categories))\n",
    "\n",
    "cont_means = X[cont_cols].mean().values\n",
    "cont_stds  = X[cont_cols].std(ddof=0).replace(0, 1).values\n",
    "\n",
    "def df_to_tensors(frame):\n",
    "    x_categ = torch.tensor(frame[cat_cols].apply(lambda s: s.cat.codes).values, dtype=torch.long)\n",
    "    x_cont  = torch.tensor(((frame[cont_cols].values - cont_means) / cont_stds), dtype=torch.float32)\n",
    "    y       = torch.tensor(frame[target_col].values, dtype=torch.float32).unsqueeze(1)\n",
    "    return x_categ, x_cont, y\n",
    "\n",
    "x_categ, x_cont, y = df_to_tensors(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = TabTransformer(\n",
    "    categories=tuple(category_sizes),\n",
    "    num_continuous=len(cont_cols),\n",
    "    dim=32,\n",
    "    depth=4,\n",
    "    heads=4,\n",
    "    attn_dropout=0.1,\n",
    "    ff_dropout=0.1,\n",
    "    mlp_hidden_mults=(4, 2),\n",
    "    mlp_act=nn.ReLU(),\n",
    "    dim_out=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
